---
import { getCollection } from 'astro:content';
import WorkContent from '../components/WorkContent.astro';

const events = await getCollection('events');
const works = await getCollection('works');

const workMap = new Map(works.map(w => [w.data.title.toLowerCase(), w]));

let audioPosts = events
  .filter(e => e.data.audio)
  .map(e => {
    const w = workMap.get(e.data.work?.toLowerCase());
    return {
      event: e,
      workDesc: w?.data.description || '',
      workUrl: w ? `/works/${w.slug}/` : '',
      workSlug: w?.slug
    };
  });

// Shuffle the posts
for (let i = audioPosts.length - 1; i > 0; i--) {
  const j = Math.floor(Math.random() * (i + 1));
  [audioPosts[i], audioPosts[j]] = [audioPosts[j], audioPosts[i]];
}
---
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>Listen</title>

<style>
:root { --fadeTime: 3000ms; }

body {
  margin: 0;
  background: black;
  color: white;
  font-family: monospace;
  overflow: hidden;
}

/* generic fade */
.fade {
  opacity: 0;
  transition: opacity var(--fadeTime) linear;
  pointer-events: none;
}
.fade.visible {
  opacity: 1;
  pointer-events: auto;
}

/* INFO HUD */
#info-hud {
  position: fixed;
  top: 20px;
  left: 20px;
  right: 26%;
  line-height: 1.4;
}

/* TRACK LIST */
#works-hud {
  position: fixed;
  top: 50%;
  left: 20px;
  transform: translateY(-50%);
  max-height: 40vh;
  width: 25%;
  overflow-y: auto;
  mask-image: linear-gradient(to bottom, transparent, white 10%, white 90%, transparent);
}
#works-hud ul { list-style: none; padding: 0; margin: 0; }
#works-hud li { padding: 6px 0; cursor: pointer; opacity: .35; transition: opacity 200ms; }
#works-hud li.selected { opacity: 1; }
#works-hud.visible { opacity: .8; pointer-events: auto; }

/* SPECTROGRAM */
#spectrogram-container {
  position: fixed;
  bottom: 0;
  left: 0;
  width: 100vw;
  height: 40vh;
}
#spectrogram {
  width: 100%;
  height: 100%;
  display: block;
}
#playhead {
  position: absolute;
  top: 0;
  bottom: 0;
  width: 3px;
  background: white;
  mix-blend-mode: difference;
  pointer-events: none;
}
#time-display {
  position: fixed;
  bottom: 10px;
  font-size: 12px;
  color: white;
  pointer-events: none;
  white-space: nowrap;
  transform: translateX(-50%);
  transition: left 0.1s ease-out;
  z-index: 1000;
}

/* MODAL */
#modal {
  position: fixed;
  top: 0;
  right: 0;
  width: 75vw;
  height: 60vh;
  background: black;
  padding: 40px;
  overflow-y: auto;
  opacity: 0;
  pointer-events: none;
  transition: opacity var(--fadeTime) linear;
}
#modal.visible {
  opacity: 1;
  pointer-events: auto;
}

/* HELP */
#helpToggle {
  position: fixed;
  bottom: 20px;
  right: 20px;
  opacity: .65;
  cursor: pointer;
  user-select: none;
}
#help {
  position: fixed;
  bottom: 55px;
  right: 20px;
  font-size: 12px;
  opacity: 0;
  pointer-events: none;
  transition: opacity var(--fadeTime) linear;
}
#help.visible { opacity: .75; }
#help span { display: block; opacity: .7; }

/* EXIT */
#exit {
  position: fixed;
  top: 10px;
  right: 20px;
  font-size: 2em;
  text-decoration: none;
  color: white;
  opacity: .5;
}
</style>
</head>

<body>

<a id="exit" href="/">&times;</a>

<div id="info-hud" class="fade"></div>

<div id="works-hud" class="visible">
  <ul>
    {audioPosts.map((p,i)=>(
      <li class={i===0?'selected':''}
          data-audio={p.event.data.audio}
          data-work={p.event.data.work}
          data-desc={p.workDesc}
          data-perf={JSON.stringify(p.event.data.performedBy || null)}
          data-event={p.event.data.eventName}
          data-venue={p.event.data.venue}
          data-city={p.event.data.city}
          data-country={p.event.data.country}
          data-date={p.event.data.dates?.[0]}
          data-workurl={p.workUrl}>
        {p.event.data.work}
        <div class="modal-content" style="display: none;">
          <WorkContent slug={p.workSlug} />
        </div>
      </li>
    ))}
  </ul>
</div>

<div id="spectrogram-container" class="fade visible">
  <canvas id="spectrogram"></canvas>
  <div id="playhead"></div>
</div>
<div id="time-display">0:00</div>

<div id="modal"></div>

<div id="helpToggle">?</div>
<div id="help">
  <span>ESC exit / close modal</span>
  <span>SPACE play / pause</span>
  <span>f fullscreen</span>
  <span>m minimal</span>
  <span>i modal</span>
  <span>? help</span>
  <span>↑ ↓ navigate</span>
  <span>click seek</span>
</div>

<script>
const fadeTime = 3000;
document.documentElement.style.setProperty('--fadeTime', fadeTime+'ms');

const infoHUD = document.getElementById('info-hud');
const worksHUD = document.getElementById('works-hud');
const specC = document.getElementById('spectrogram-container');
const modal = document.getElementById('modal');
const help = document.getElementById('help');
const helpToggle = document.getElementById('helpToggle');

const canvas = document.getElementById('spectrogram');
const ctx = canvas.getContext('2d');
const playhead = document.getElementById('playhead');
const timeDisplay = document.getElementById('time-display');
const items = [...worksHUD.querySelectorAll('li')];

let audioCtx, gainNode, source, buffer;
let selected = 0;
let minimal = false;
let switching = false;
let playheadRAF = 0;
let changeTrackId = 0;
let userHasInteracted = false; // Track if user has interacted

let isPlaying = false;
let pausedAt = 0;
let startTime = 0;

/* ---------- helpers ---------- */
function formatPerformers(p) {
  if (!p) return '';

  const arr = Array.isArray(p) ? p : [p];

  return arr
    .map(s => s.replace(/\[\[|\]\]/g, '').trim())
    .join(', ');
}

function year(d){ return d?.match(/^(\d{4})/)?.[1] || ''; }
function show(el){ el.classList.add('visible'); }
function hide(el){ el.classList.remove('visible'); }
function sleep(ms){ return new Promise(r=>setTimeout(r,ms)); }

/* ---------- time formatting ---------- */
function formatTime(seconds) {
  const mins = Math.floor(seconds / 60);
  const secs = Math.floor(seconds % 60);
  return `${mins}:${secs.toString().padStart(2, '0')}`;
}

/* ---------- resize ---------- */
function resize(){
  canvas.width = window.innerWidth;
  canvas.height = window.innerHeight * 0.4;
  if (buffer) renderSpectrogramTimeline(buffer);
}
window.addEventListener('resize', resize);
document.addEventListener('fullscreenchange', resize);

/* ---------- HUD ---------- */
function updateHUD(el){
  infoHUD.innerHTML = `
    ${el.dataset.work}<br>
    ${el.dataset.desc}<br>
    ${formatPerformers(JSON.parse(el.dataset.perf || 'null'))}<br>    
    ${el.dataset.event}<br>
    ${el.dataset.venue}, ${el.dataset.city}, ${el.dataset.country}<br>
    ${year(el.dataset.date)}
  `;
}

/* ---------- audio ---------- */
async function ensureAudio(){
  if(!audioCtx){
    audioCtx = new AudioContext();
    gainNode = audioCtx.createGain();
    gainNode.gain.value = 0; // Keep silent until user interaction
    gainNode.connect(audioCtx.destination);
    console.log('Audio context created, gain set to 0');
  }
  // NEVER resume automatically - wait for explicit user interaction
}

function stopSource(){
  if(!source || !audioCtx || !buffer) return;

  pausedAt = audioCtx.currentTime - startTime;
  pausedAt = Math.max(0, Math.min(pausedAt, buffer.duration));

  try{ source.stop(); }catch{}
  try{ source.disconnect(); }catch{}

  source = null;
  isPlaying = false;
  console.log('Source stopped, isPlaying:', isPlaying);
}

async function fadeTo(target){
  console.log('Fading to gain:', target);
  const now = audioCtx.currentTime;
  gainNode.gain.cancelScheduledValues(now);
  gainNode.gain.setValueAtTime(gainNode.gain.value, now);
  gainNode.gain.linearRampToValueAtTime(target, now + fadeTime/1000);
  await sleep(fadeTime);
  console.log('Fade complete, current gain:', gainNode.gain.value);
}

function cancelPlayhead(){
  if(playheadRAF) cancelAnimationFrame(playheadRAF);
  playheadRAF = 0;
}

function startPlayhead(offset){
  console.log('Starting playhead with offset:', offset);
  const start = audioCtx.currentTime - offset;
  const loop = () => {
    if(!source || !buffer) return;
    const t = audioCtx.currentTime - start;
    const progress = t / buffer.duration;
    const position = progress * 100;
    
    playhead.style.left = `${position}%`;
    
    // Update time display with positioning logic
    const timeText = formatTime(t);
    timeDisplay.textContent = timeText;
    
    // Position time display: follow playhead, but align left when in last 20%
    const windowWidth = window.innerWidth;
    const thresholdPosition = 80; // 80% = last 20%
    
    if (position >= thresholdPosition) {
      // In the last 20%, align to the left edge of the playhead
      timeDisplay.style.left = `${position}%`;
      timeDisplay.style.transform = 'translateX(0)';
    } else {
      // Normal positioning: centered on playhead
      timeDisplay.style.left = `${position}%`;
      timeDisplay.style.transform = 'translateX(-50%)';
    }
    
    playheadRAF = requestAnimationFrame(loop);
  };
  loop();
}

/* ---------- spectrogram (unchanged FFT version) ---------- */
function hann(n,N){ return 0.5-0.5*Math.cos(2*Math.PI*n/(N-1)); }
function fftRadix2(re,im){
  const N=re.length;let j=0;
  for(let i=0;i<N;i++){
    if(i<j){[re[i],re[j]]=[re[j],re[i]];[im[i],im[j]]=[im[j],im[i]];}
    let m=N>>1;while(m>=1&&j>=m){j-=m;m>>=1;}j+=m;
  }
  for(let len=2;len<=N;len<<=1){
    const ang=-2*Math.PI/len,wlenRe=Math.cos(ang),wlenIm=Math.sin(ang);
    for(let i=0;i<N;i+=len){
      let wRe=1,wIm=0;
      for(let k=0;k<len/2;k++){
        const uRe=re[i+k],uIm=im[i+k];
        const vRe=re[i+k+len/2]*wRe-im[i+k+len/2]*wIm;
        const vIm=re[i+k+len/2]*wIm+im[i+k+len/2]*wRe;
        re[i+k]=uRe+vRe;im[i+k]=uIm+vIm;
        re[i+k+len/2]=uRe-vRe;im[i+k+len/2]=uIm-vIm;
        const nRe=wRe*wlenRe-wIm*wlenIm;
        wIm=wRe*wlenIm+wIm*wlenRe;wRe=nRe;
      }
    }
  }
}

function renderSpectrogramTimeline(buf){
  const W=canvas.width,H=canvas.height;
  ctx.clearRect(0,0,W,H);
  const N=2048,half=N>>1,ch=buf.getChannelData(0);
  const hop=Math.max(1,Math.floor((ch.length-N)/W));
  const re=new Array(N),im=new Array(N),mag=new Float32Array(half);

  for(let x=0;x<W;x++){
    const start=x*hop;
    if(start+N>=ch.length) break;
    for(let i=0;i<N;i++){re[i]=ch[start+i]*hann(i,N);im[i]=0;}
    fftRadix2(re,im);
    let max=1e-9;
    for(let k=0;k<half;k++){mag[k]=Math.hypot(re[k],im[k]);if(mag[k]>max)max=mag[k];}
    for(let y=0;y<H;y++){
      const k=Math.floor(y/H*half);
      const v=Math.log10(1+9*(mag[k]/max));
      const g=Math.floor(v*255);
      ctx.fillStyle=`rgb(${g},${g},${g})`;
      ctx.fillRect(x,H-y-1,1,1);
    }
  }
}

/* ---------- playback ---------- */
async function loadBuffer(file){
  console.log('Loading buffer for file:', file);
  const r=await fetch('/audio/'+encodeURIComponent(file));
  return audioCtx.decodeAudioData(await r.arrayBuffer());
}

function startPlayback(offset=0){
  // NEVER start without user interaction
  if (!userHasInteracted) {
    console.log('BLOCKING playback: user has not interacted yet');
    return;
  }
  
  console.log('Starting playback with offset:', offset, 'current gain:', gainNode.gain.value);
  stopSource();
  cancelPlayhead();

  source = audioCtx.createBufferSource();
  source.buffer = buffer;
  source.connect(gainNode);

  startTime = audioCtx.currentTime - offset;
  source.start(0, offset);

  isPlaying = true;
  startPlayhead(offset);
}

async function togglePlayPause(){
  if(!buffer) return;

  if(isPlaying){
    console.log('Pausing playback');
    await fadeTo(0);
    stopSource();
  } else {
    console.log('Starting playback from togglePlayPause');
    userHasInteracted = true; // Mark that user has interacted
    await ensureAudio();
    startPlayback(pausedAt || 0);
    await fadeTo(1);
  }
}

async function changeTrack(i) {
  if (i < 0 || i >= items.length) return;

  const currentChangeId = ++changeTrackId;
  switching = true;

  const el = items[i];
  items[selected]?.classList.remove('selected');
  selected = i;
  el.classList.add('selected');
  el.scrollIntoView({ behavior: 'smooth', block: 'center' });

  updateHUD(el);
  await ensureAudio();

  // Stop any playing sound and fade out
  if (isPlaying) {
    console.log('Stopping current track during track change');
    await fadeTo(0);
    stopSource();
  }
  
  // Hide elements for the transition
  hide(infoHUD);
  hide(worksHUD);
  hide(specC);
  
  // If another track change was initiated, abort this one.
  if (currentChangeId !== changeTrackId) {
    switching = false;
    return;
  }

  try {
    buffer = await loadBuffer(el.dataset.audio);
  } catch(e) {
    console.error("Failed to load audio:", e);
    if (currentChangeId === changeTrackId) switching = false;
    // still show the HUDs
    show(infoHUD);
    show(worksHUD);
    return;
  }

  if (currentChangeId !== changeTrackId) {
    switching = false;
    return;
  }

  pausedAt = 0;
  renderSpectrogramTimeline(buffer);
  // Don't auto-play - just load the track and wait for user interaction

  // Show elements but don't fade in audio yet
  show(infoHUD);
  show(worksHUD);
  show(specC);

  if (currentChangeId === changeTrackId) {
    switching = false;
  }
}

/* ---------- modal ---------- */
function toggleModal(){
  if(modal.classList.contains('visible')){
    hide(modal); return;
  }
  modal.innerHTML='';

  const contentEl = items[selected].querySelector('.modal-content');
  if (contentEl) {
    modal.innerHTML = contentEl.innerHTML;
  }
  
  show(modal);
}

/* ---------- events ---------- */
items.forEach((el,i)=>el.onclick=()=>{
  console.log('Track clicked, index:', i);
  userHasInteracted = true; // Mark user interaction
  changeTrack(i);
});

canvas.onclick=e=>{
  console.log('Canvas clicked');
  userHasInteracted = true; // Mark user interaction
  if(!buffer) return;
  const r=canvas.getBoundingClientRect();
  const t=(e.clientX-r.left)/r.width*buffer.duration;
  startPlayback(Math.max(0,t));
};

// Add user interaction detection for first interaction
document.addEventListener('click', ()=>{
  if (!userHasInteracted) {
    console.log('First user interaction detected');
    userHasInteracted = true;
  }
}, { once: true });

document.addEventListener('keydown',e=>{
  if(e.code==='Space'){ 
    e.preventDefault(); 
    console.log('Space pressed, toggling play/pause');
    userHasInteracted = true; // Mark user interaction
    togglePlayPause(); 
  }
  if(e.key==='ArrowUp') changeTrack(selected-1);
  if(e.key==='ArrowDown') changeTrack(selected+1);
  if(e.key==='i') toggleModal();
  if(e.key==='m'){ minimal=!minimal; minimal?(hide(infoHUD),hide(worksHUD),hide(specC),hide(timeDisplay)):(show(infoHUD),show(worksHUD),show(specC),show(timeDisplay)); }
  if(e.key==='f') document.fullscreenElement?document.exitFullscreen():document.documentElement.requestFullscreen();
  if(e.key==='Escape') modal.classList.contains('visible')?hide(modal):location.href='/';
  if(e.key==='?') help.classList.toggle('visible');
});

helpToggle.onclick=()=>help.classList.toggle('visible');

/* ---------- start ---------- */
async function init() {
  console.log('Initializing audio player');
  resize();
  const el = items[selected]; // selected is 0
  updateHUD(el);

  // Create audio context WITHOUT resuming it, so we can decode
  if (!audioCtx) {
    audioCtx = new AudioContext();
    gainNode = audioCtx.createGain();
    gainNode.gain.value = 0; // Start silent
    gainNode.connect(audioCtx.destination);
    console.log('Audio context created in init, gain set to 0');
  }

  try {
    // Load buffer for the first track
    buffer = await loadBuffer(el.dataset.audio);
    pausedAt = 0; // ready to play from start
    renderSpectrogramTimeline(buffer);
    console.log('Initial track loaded, no auto-playback');
  } catch (e) {
    console.error("Failed to load initial audio:", e);
  }

  // Show UI elements
  show(infoHUD);
  show(worksHUD);
  show(specC);
}

init();
</script>

</body>
</html>
