<div
  id="three-container"
  style="position: absolute; top: 0; left: 0; width: 100%; height: 100vh; z-index: 0; background: linear-gradient(to bottom, #000022, #000033);"
>
  <button
    id="start-audio-btn"
    style="position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); padding: 15px 30px; background-color: rgba(0, 0, 0, 0.8); color: #fff; border: 2px solid #0ff; border-radius: 5px; font-family: sans-serif; font-size: 18px; cursor: pointer; box-shadow: 0 0 20px rgba(0, 255, 255, 0.5); z-index: 1000; display: none;"
  >
    Start Audio Experience
  </button>
</div>

<script>
  import * as THREE from "three";
  import { OrbitControls } from "three/examples/jsm/controls/OrbitControls.js";
  import { EffectComposer } from "three/examples/jsm/postprocessing/EffectComposer.js";
  import { RenderPass } from "three/examples/jsm/postprocessing/RenderPass.js";
  import { UnrealBloomPass } from "three/examples/jsm/postprocessing/UnrealBloomPass.js";
  import { ShaderPass } from "three/examples/jsm/postprocessing/ShaderPass.js";
  import { SimplexNoise } from "three/examples/jsm/math/SimplexNoise.js";
  import * as Tone from "tone";
  import TWEEN from "@tweenjs/tween.js";
  import SphereModule from "./sphereModule.js";
  import CubeModule from "./cubeModule.js";
  import PulseModule from "./pulseModule.js";
  import AudioMixer from "./audioMixer.js";

  // Initialize Three.js variables
  let scene = new THREE.Scene();
  let camera = new THREE.PerspectiveCamera(
    75,
    window.innerWidth / window.innerHeight,
    0.1,
    1000,
  );
  let renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
  let composer: any;
  let controls: any;
  let pulse: any;
  let cube: any;
  let reverb: any;
  let listener: any;
  let reverbGain: any;
  let floatingModel: any; // Reference for the floating model
  let threeAudioListener: THREE.AudioListener; // Three.js audio listener
  let positionalAudios: THREE.PositionalAudio[] = []; // Track positional audio sources

  // Initialize modules
  let cubeModule: any;
  let pulseModule: any;
  let sphereModule: any;
  let audioMixer: any;
  let clock = new THREE.Clock(); // Add clock for timing

  // Track initial volume and scroll state
  let initialVolume = 0;
  let lastScrollY = 0;
  let toneStarted = false;

  // Spatial audio objects and movement parameters
  let audioObjects: any[] = [];
  const SPACE_BOUNDS = 20; // Changed from 800 to 20 to keep objects in -10 to 10 range
  const BASE_FREQUENCY = 220; // A3 as base frequency
  const FREQUENCY_STEP = 20; // 20 Hz steps for microtonal distribution
  const MAX_OBJECTS = 15; // Maximum number of objects in the scene
  const COLLISION_THRESHOLD = 1.5; // Distance threshold for collision detection

  // Physics parameters
  const MIN_SPEED = 0.0005; // Reduced by 10x for much slower movement (was 0.005)
  const MAX_SPEED = 0.002; // Reduced by 10x for much slower movement (was 0.02)
  const DAMPING = 0.99; // Increased damping for smoother movement
  const ATTRACTION_FORCE = 0.00002; // Reduced for wider initial spread, but still pulls back to center
  const REPULSION_THRESHOLD = 100; // Distance threshold for repulsion effect
  const REPULSION_FORCE = 0.00001; // Force to push objects away from center initially

  // Lighting parameters
  const LIGHT_EXPANSION_FACTOR = 3; // Light expansion factor
  const LIGHT_ROTATION_SPEED = 0.005; // Light rotation speed

  // Sphere parameters
  const SPHERE_GROWTH_FACTOR = 2.5; // Increased from 1.5 for more dramatic growth
  const SPHERE_GROWTH_SPEED = 0.0017; // Reduced by 3x from 0.005 for slower growth
  const SPHERE_MIN_TRANSPARENCY = 0.08; // Reduced from 0.1 (20% more transparent)
  const SPHERE_MAX_TRANSPARENCY = 0.4; // Reduced from 0.5 (20% more transparent)
  const SPHERE_SIZE_MULTIPLIER = 10.0; // Make spheres 10 times bigger (increased from 5)

  // Cube parameters
  const CUBE_SIZE_MULTIPLIER = 10.0; // Make cubes 10 times bigger

  // Enhanced lighting objects
  let lightingBars: any[] = [];

  // Godray shader parameters
  const godrayParams = {
    density: 1.0, // Doubled from 0.5
    maxDensity: 1.6, // Doubled from 0.8
    distanceAttenuation: 2.0,
    raymarchSteps: 30, // Increased from 20 for better quality
    lightPos: new THREE.Vector3(0, 10, 0),
    noiseResolution: new THREE.Vector2(256, 256),
    texelSizeY: 0.01,
    lightCameraNear: 0.1,
    lightCameraFar: 100,
    near: 0.1,
    far: 1000,
  };

  // Load shader files
  let godrayVertexShader;
  let godrayFragmentShader;

  // Simplified godray shader for spheres
  const simplifiedGodrayVertexShader = `
    varying vec3 vNormal;
    varying vec3 vWorldPosition;
    varying vec3 vViewPosition;
    varying vec2 vUv;
    
    void main() {
      vUv = uv;
      vNormal = normalize(normalMatrix * normal);
      vec4 worldPosition = modelMatrix * vec4(position, 1.0);
      vWorldPosition = worldPosition.xyz;
      
      vec4 mvPosition = viewMatrix * worldPosition;
      vViewPosition = -mvPosition.xyz;
      
      gl_Position = projectionMatrix * mvPosition;
    }
  `;

  const simplifiedGodrayFragmentShader = `
    uniform vec3 color;
    uniform float time;
    uniform vec3 lightPos;
    uniform float transparency;
    
    varying vec3 vNormal;
    varying vec3 vWorldPosition;
    varying vec3 vViewPosition;
    varying vec2 vUv;
    
    void main() {
      // Fresnel effect for edge glow
      vec3 viewDirection = normalize(vViewPosition);
      float fresnel = pow(1.0 - abs(dot(vNormal, viewDirection)), 3.0);
      
      // Light ray effect
      vec3 lightDir = normalize(lightPos - vWorldPosition);
      float lightIntensity = pow(max(0.0, dot(vNormal, lightDir)), 2.0);
      
      // Pulsating glow
      float pulse = 0.5 + 0.5 * sin(time * 2.0);
      
      // God ray effect - doubled energy
      float rayEffect = 0.0;
      float steps = 15.0; // Increased from 10 for better quality
      vec3 rayStart = vWorldPosition;
      vec3 rayEnd = lightPos;
      vec3 rayDir = normalize(rayEnd - rayStart);
      float rayLength = distance(rayEnd, rayStart);
      
      for(float i = 0.0; i < steps; i++) {
        float t = i / steps;
        vec3 samplePoint = mix(rayStart, rayEnd, t);
        float distFromLight = distance(samplePoint, lightPos);
        float distFactor = 1.0 - (distFromLight / rayLength);
        
        // Add more intensity when ray aligns with view direction
        float alignment = pow(max(0.0, dot(rayDir, viewDirection)), 4.0);
        
        rayEffect += distFactor * alignment * 0.2; // Doubled from 0.1
      }
      
      // Volumetric light effect - doubled energy
      float volumetricEffect = pow(max(0.0, dot(viewDirection, lightDir)), 4.0) * 1.0; // Doubled from 0.5
      
      // Combine effects
      vec3 glowColor = color * (fresnel * 3.0 + lightIntensity * 1.0); // Doubled intensity
      glowColor *= 0.8 + 0.8 * pulse; // Increased pulse effect
      
      // Add ray effects - doubled energy
      glowColor += color * rayEffect * pulse * 2.0;
      glowColor += color * volumetricEffect * pulse * 2.0;
      
      // Final color with dynamic transparency
      gl_FragColor = vec4(glowColor, fresnel * 0.3 + transparency);
    }
  `;

  // Camera rotation parameters
  const CAMERA_ROTATION_SPEED_X = 0.00005; // Slowed down for very slow movement
  const CAMERA_ROTATION_SPEED_Y = 0.00007; // Slowed down for very slow movement
  const CAMERA_ROTATION_SPEED_Z = 0.00003; // Slowed down for very slow movement
  const CAMERA_ROTATION_RADIUS_MIN = 8; // Minimum radius
  const CAMERA_ROTATION_RADIUS_MAX = 20; // Maximum radius (reduced from 40 to be closer)
  const CAMERA_INERTIA = 0.98; // Camera inertia factor
  const CAMERA_MAX_DISTANCE = 100; // Maximum distance from origin in any direction
  let cameraRotationAngle = 0; // Current camera rotation angle
  let cameraAutoRotationEnabled = true; // Flag to enable/disable auto rotation
  let cameraVelocity = new THREE.Vector3(0, 0, 0); // Camera velocity for inertia
  let cameraTargetPosition = new THREE.Vector3(0, 0, 0); // Target position for smooth movement

  // HUD parameters
  let hudElement: HTMLElement | null;
  let hudVisible = true;

  // Audio samples for grain player
  const AUDIO_SAMPLES = [
    "/audio/heroic.mp3", // We'll need to add this file to the public/audio directory
  ];

  // Grain player for spheres
  let grainPlayers: any[] = [];

  // White noise generators for bars
  let noiseGenerators: any[] = [];

  // Biquad filter parameters
  const FILTER_RESONANCE = 10; // High resonance for DJ-style filter sweeps
  const FILTER_MIN_FREQ = 80; // 80Hz minimum frequency
  const FILTER_MAX_FREQ = 8000; // 8kHz maximum frequency
  const FILTER_SWEEP_SPEED = 0.5; // Speed of filter sweeps
  let filterSweeps: any[] = [];

  // Lower octave parameters
  const LOW_OCTAVE_FREQUENCIES = [
    55, // A1 (2 octaves below A3)
    65.4, // C2 (2 octaves below C4)
    82.4, // E2 (2 octaves below E4)
    98, // G2 (2 octaves below G4)
    110, // A2 (2 octaves below A4)
  ];
  let lowOctaveSynths: any[] = [];

  // Create a lighting bar with dynamic properties
  const createLightingBar = (index: number) => {
    // Create a cylinder geometry for the lighting bar
    const height = (Math.random() * 4 + 2) * 5; // 5 times bigger
    const radius = (Math.random() * 0.3 + 0.1) * 5; // 5 times bigger
    const geometry = new THREE.CylinderGeometry(radius, radius, height, 16, 1);

    // Create a material with random color
    const hue = Math.random();
    const saturation = 0.9;
    const lightness = 0.6;
    const color = new THREE.Color().setHSL(hue, saturation, lightness);

    // Create emissive material for glow effect
    const material = new THREE.MeshPhongMaterial({
      color: color,
      emissive: color.clone(),
      emissiveIntensity: 0.8,
      transparent: true,
      opacity: 0.7,
      shininess: 100,
    });

    // Create mesh
    const mesh = new THREE.Mesh(geometry, material);

    // Random position within bounds (-10 to 10)
    mesh.position.set(
      (Math.random() - 0.5) * 20, // Changed from SPACE_BOUNDS * 0.5 to 20
      (Math.random() - 0.5) * 20, // Changed from SPACE_BOUNDS * 0.5 to 20
      (Math.random() - 0.5) * 20, // Changed from SPACE_BOUNDS * 0.5 to 20
    );

    // Random rotation
    mesh.rotation.set(
      Math.random() * Math.PI,
      Math.random() * Math.PI,
      Math.random() * Math.PI,
    );

    // Add point light at the center of the bar
    const light = new THREE.PointLight(color, 1, 50); // Increased light distance to match larger size
    light.position.set(0, 0, 0);
    mesh.add(light);

    // Random velocity for movement - ensure all bars move
    const velocity = new THREE.Vector3(
      ((Math.random() - 0.5) * MIN_SPEED * 2 || MIN_SPEED * 0.5) / 10, // 10 times slower
      ((Math.random() - 0.5) * MIN_SPEED * 2 || MIN_SPEED * 0.5) / 10,
      ((Math.random() - 0.5) * MIN_SPEED * 2 || MIN_SPEED * 0.5) / 10,
    );

    // Random rotation velocity
    const rotationVelocity = new THREE.Vector3(
      ((Math.random() - 0.5) * LIGHT_ROTATION_SPEED * 2) / 10, // 10 times slower
      ((Math.random() - 0.5) * LIGHT_ROTATION_SPEED * 2) / 10,
      ((Math.random() - 0.5) * LIGHT_ROTATION_SPEED * 2) / 10,
    );

    // Initial scale
    const initialScale = new THREE.Vector3(1, 1, 1);

    // Vertical ping-pong movement parameters
    const verticalMovement = {
      enabled: true,
      amplitude: Math.random() * 3 + 1, // Random amplitude between 1-4
      speed: (Math.random() * 0.001 + 0.0005) / 10, // 10 times slower
      phase: Math.random() * Math.PI * 2, // Random starting phase
    };

    // Breathing effect parameters
    const breathingEffect = {
      enabled: true,
      minScale: 0.8, // Minimum scale during breathing
      maxScale: 1.2, // Maximum scale during breathing
      speed: (Math.random() * 0.001 + 0.0005) / 10, // 10 times slower
      phase: Math.random() * Math.PI * 2, // Random starting phase
    };

    // Add to scene
    scene.add(mesh);

    // Calculate frequency for color changes
    const frequency = BASE_FREQUENCY + index * FREQUENCY_STEP * 1.5;

    // Create white noise with biquad filter for the bar
    if (Tone.context.state === "running") {
      // Create noise source
      const noise = new Tone.Noise({
        type: "white",
        volume: -30,
      });

      // Create biquad filter
      const filter = new Tone.Filter({
        type: "bandpass",
        frequency: frequency,
        Q: 1.0,
      });

      // Connect noise to filter and to mixer or destination
      noise.connect(filter);

      // Connect to mixer
      if (audioMixer) {
        audioMixer.connectNode(filter, "lightingBarNoise");
      } else {
        // Fallback to old connection method
        filter.toDestination();
        if (reverb) {
          filter.connect(reverb);
        }
      }

      // Start noise
      noise.start();

      // Store noise and filter in noiseGenerators array
      noiseGenerators.push({
        noise,
        filter,
        bar: mesh,
        baseFreq: frequency,
      });
    }

    return {
      mesh,
      light,
      velocity,
      rotationVelocity,
      initialScale,
      frequency,
      color,
      expansionState: 0, // 0 to 1 for expansion animation
      expansionDirection: 1, // 1 for expanding, -1 for contracting
      lastUpdate: Date.now(),
      verticalMovement,
      breathingEffect,
      initialY: mesh.position.y, // Store initial Y position for ping-pong movement
    };
  };

  // Update lighting bars
  const updateLightingBars = (deltaTime: number, now: number) => {
    lightingBars.forEach((bar, index) => {
      // Move the bar
      bar.mesh.position.x += bar.velocity.x * deltaTime;
      bar.mesh.position.y += bar.velocity.y * deltaTime;
      bar.mesh.position.z += bar.velocity.z * deltaTime;

      // Apply vertical ping-pong movement
      if (bar.verticalMovement && bar.verticalMovement.enabled) {
        const verticalOffset =
          Math.sin(
            now * bar.verticalMovement.speed + bar.verticalMovement.phase,
          ) * bar.verticalMovement.amplitude;
        bar.mesh.position.y = bar.initialY + verticalOffset;
      }

      // Rotate the bar
      bar.mesh.rotation.x += bar.rotationVelocity.x * deltaTime;
      bar.mesh.rotation.y += bar.rotationVelocity.y * deltaTime;
      bar.mesh.rotation.z += bar.rotationVelocity.z * deltaTime;

      // Update expansion state (10 times slower)
      bar.expansionState += (bar.expansionDirection * 0.005 * deltaTime) / 10;

      // Reverse direction at limits
      if (bar.expansionState >= 1) {
        bar.expansionDirection = -1;
        bar.expansionState = 1;
      } else if (bar.expansionState <= 0) {
        bar.expansionDirection = 1;
        bar.expansionState = 0;
      }

      // Calculate expansion scale
      const expansionScale =
        1 + (LIGHT_EXPANSION_FACTOR - 1) * bar.expansionState;

      // Apply breathing effect
      let finalScale = expansionScale;
      if (bar.breathingEffect && bar.breathingEffect.enabled) {
        const breathingFactor =
          bar.breathingEffect.minScale +
          (Math.sin(
            now * bar.breathingEffect.speed + bar.breathingEffect.phase,
          ) *
            0.5 +
            0.5) *
            (bar.breathingEffect.maxScale - bar.breathingEffect.minScale);

        finalScale *= breathingFactor;
      }

      bar.mesh.scale.set(finalScale, finalScale, finalScale);

      // Update light color based on expansion (pitch relationship)
      const hueShift = bar.expansionState * 0.2; // Shift hue by up to 0.2
      const newHue = (bar.color.getHSL({}).h + hueShift) % 1;
      const newColor = new THREE.Color().setHSL(
        newHue,
        bar.color.getHSL({}).s,
        bar.color.getHSL({}).l + bar.expansionState * 0.2, // Increase lightness with expansion
      );

      // Apply new color to light and material
      bar.light.color.copy(newColor);
      bar.mesh.material.emissive.copy(newColor);

      // Adjust light intensity based on expansion
      bar.light.intensity = 0.5 + bar.expansionState * 2;

      // Update noise filter parameters based on expansion state
      if (noiseGenerators[index]) {
        const noiseGen = noiseGenerators[index];

        // Adjust filter frequency based on expansion state
        // Higher Q when expanded, lower Q when contracted
        const newQ = 0.5 + bar.expansionState * 5;
        noiseGen.filter.Q.value = newQ;

        // Adjust filter frequency slightly based on expansion
        const freqMultiplier = 0.8 + bar.expansionState * 0.4;
        noiseGen.filter.frequency.value = noiseGen.baseFreq * freqMultiplier;

        // Adjust volume based on expansion
        const volume = -40 + bar.expansionState * 20;
        noiseGen.noise.volume.value = volume;
      }

      // Boundary checks with bounce
      const halfBounds = SPACE_BOUNDS / 2;

      if (Math.abs(bar.mesh.position.x) > halfBounds) {
        bar.velocity.x *= -1;
        bar.mesh.position.x = Math.sign(bar.mesh.position.x) * halfBounds;
      }

      if (
        Math.abs(bar.mesh.position.y) > halfBounds &&
        !bar.verticalMovement.enabled
      ) {
        bar.velocity.y *= -1;
        bar.mesh.position.y = Math.sign(bar.mesh.position.y) * halfBounds;
      }

      if (Math.abs(bar.mesh.position.z) > halfBounds) {
        bar.velocity.z *= -1;
        bar.mesh.position.z = Math.sign(bar.mesh.position.z) * halfBounds;
      }
    });
  };

  // Initialize lighting bars
  const initLightingBars = () => {
    // Clear existing bars
    lightingBars.forEach((bar) => {
      if (bar.mesh) scene.remove(bar.mesh);
    });

    lightingBars = [];

    // Create new bars
    const barCount = 5;
    for (let i = 0; i < barCount; i++) {
      lightingBars.push(createLightingBar(i));
    }

    console.log(`Created ${lightingBars.length} lighting bars`);
  };

  // Add audio context auto-resume functionality
  const setupAudioContextResumption = () => {
    if (!Tone.context) return;

    // Function to resume audio context
    const resumeAudioContext = async () => {
      if (Tone.context.state !== "running") {
        try {
          await Tone.context.resume();
          console.log("Audio context resumed:", Tone.context.state);

          // Update audio modules with the resumed context
          if (cubeModule) cubeModule.updateAudioContext(Tone.context);
          if (sphereModule) sphereModule.updateAudioContext(Tone.context);
          if (pulseModule) pulseModule.updateAudioContext(Tone.context);
          if (audioMixer) audioMixer.updateAudioContext(Tone.context);
        } catch (err) {
          console.error("Failed to resume audio context:", err);
        }
      }
    };

    // Resume on various user interactions
    const userInteractions = ["click", "touchstart", "keydown", "mousedown"];
    userInteractions.forEach((event) => {
      window.addEventListener(event, resumeAudioContext, { once: false });
    });

    // Resume when window gets focus
    window.addEventListener("focus", resumeAudioContext);

    // Set up periodic check to ensure audio context stays running
    setInterval(() => {
      if (Tone.context && Tone.context.state !== "running") {
        console.log("Audio context suspended, attempting to resume...");
        resumeAudioContext();
      }
    }, 3000);

    // Try to resume immediately
    setTimeout(resumeAudioContext, 1000);

    console.log("Audio context resumption handlers set up");
  };

  // Create a spatial audio object with random properties
  const createAudioObject = (index: number) => {
    // Create a sphere geometry with higher detail for better shader effects
    const radius = (Math.random() * 0.8 + 0.4) * SPHERE_SIZE_MULTIPLIER; // 10x larger radius
    const geometry = new THREE.SphereGeometry(radius, 32, 32);

    // Create matcap material for translucent spheres
    const matcapTexture = new THREE.TextureLoader().load("/matcap/bluew.jpg");
    const matcapMaterial = new THREE.MeshMatcapMaterial({
      matcap: matcapTexture,
      transparent: true,
      opacity: 0.3, // 70% translucent
      side: THREE.DoubleSide,
    });

    // Create godray shader material
    const godrayMaterial = new THREE.ShaderMaterial({
      uniforms: {
        time: { value: 0 },
        density: { value: godrayParams.density },
        maxDensity: { value: godrayParams.maxDensity },
        lightPos: { value: godrayParams.lightPos.clone() },
        raymarchSteps: { value: godrayParams.raymarchSteps },
        color: { value: new THREE.Color() },
        transparency: { value: 0.5 }, // Default transparency
      },
      vertexShader: `
        varying vec3 vPosition;
        varying vec2 vUv;
        
        void main() {
          vPosition = position;
          vUv = uv;
          gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
        }
      `,
      fragmentShader: `
        uniform float time;
        uniform float density;
        uniform float maxDensity;
        uniform vec3 lightPos;
        uniform int raymarchSteps;
        uniform vec3 color;
        uniform float transparency;
        
        varying vec3 vPosition;
        varying vec2 vUv;
        
        void main() {
          // Calculate direction from fragment to light
          vec3 lightDir = normalize(lightPos - vPosition);
          
          // Calculate view ray
          vec3 viewVector = normalize(vPosition - cameraPosition);
          
          // Calculate density based on distance and angle
          float dist = length(vPosition - lightPos);
          float attenuation = 1.0 / (1.0 + 0.1 * dist + 0.01 * dist * dist);
          float pulse = sin(time * 0.5 + dist * 0.2) * 0.5 + 0.5;
          
          // Volumetric lighting effect
          float density = min(density * (1.0 + pulse), maxDensity);
          float rayDensity = max(0.0, dot(viewVector, lightDir));
          rayDensity = pow(rayDensity, 2.0) * density * attenuation;
          
          // Apply color with transparency
          vec3 finalColor = color * rayDensity;
          float alpha = min(rayDensity * 2.0, 1.0) * transparency;
          
          // Output final color with transparency
          gl_FragColor = vec4(finalColor, alpha);
        }
      `,
      transparent: true,
      blending: THREE.AdditiveBlending,
      side: THREE.DoubleSide,
      depthWrite: false,
    });

    // Decide which material to use (70% chance for matcap, 30% for godray)
    const useMaterial = Math.random() > 0.7 ? godrayMaterial : matcapMaterial;

    // Create mesh with the selected material
    const mesh = new THREE.Mesh(geometry, useMaterial);

    // Position the sphere using spherical coordinates for better distribution
    // Keep within -10 to 10 range
    const radius3D = 10 * (0.3 + Math.random() * 0.7); // Changed from SPACE_BOUNDS * 0.5 to 10
    const theta = Math.random() * Math.PI * 2; // Random angle around Y axis
    const phi = Math.acos(2 * Math.random() - 1); // Random angle from Y axis

    mesh.position.set(
      radius3D * Math.sin(phi) * Math.cos(theta),
      radius3D * Math.cos(phi),
      radius3D * Math.sin(phi) * Math.sin(theta),
    );

    // Add to scene
    scene.add(mesh);

    // Generate random color with higher saturation and lightness
    const hue = Math.random();
    const saturation = 0.7 + Math.random() * 0.3; // Higher saturation (0.7-1.0)
    const lightness = 0.6 + Math.random() * 0.3; // Higher lightness (0.6-0.9)
    const color = new THREE.Color().setHSL(hue, saturation, lightness);

    // Set color for godray material
    if (useMaterial === godrayMaterial) {
      useMaterial.uniforms.color.value = color;
    }

    // Add Three.js positional audio to some spheres (1 in 3 chance)
    if (threeAudioListener && Math.random() < 0.33) {
      try {
        // Create a positional audio source
        const sound = new THREE.PositionalAudio(threeAudioListener);

        // Configure positional audio parameters
        sound.setRefDistance(5);
        sound.setDistanceModel("exponential");
        sound.setRolloffFactor(2);
        sound.setVolume(0.3);

        // Create different types of sounds for variety
        const soundType = Math.floor(Math.random() * 3);

        if (soundType === 0) {
          // Load audio file
          const audioLoader = new THREE.AudioLoader();
          audioLoader.load(
            "/audio/heroic.mp3",
            (buffer) => {
              sound.setBuffer(buffer);
              sound.setLoop(true);
              // Random playback rate for variety
              sound.setPlaybackRate(0.5 + Math.random() * 0.5);
              sound.play();
            },
            (progress) => {
              // Optional progress tracking
            },
            (error) => {
              console.error("Error loading audio:", error);
            },
          );
        } else {
          // Create audio buffer with procedural sound
          const context = threeAudioListener.context;
          const sampleRate = context.sampleRate;
          const buffer = context.createBuffer(1, sampleRate * 2, sampleRate);
          const data = buffer.getChannelData(0);

          // Generate different waveforms based on soundType
          if (soundType === 1) {
            // Sine wave with frequency modulation
            const frequency = 220 + index * 20; // Different frequency per object
            for (let i = 0; i < data.length; i++) {
              const t = i / sampleRate;
              const modulation = Math.sin(t * 0.5) * 50;
              data[i] =
                Math.sin(2 * Math.PI * (frequency + modulation) * t) * 0.5;
            }
          } else {
            // Noise with filtering
            for (let i = 0; i < data.length; i++) {
              data[i] = (Math.random() * 2 - 1) * 0.5;
            }

            // Simple low-pass filter
            for (let i = 1; i < data.length; i++) {
              data[i] = (data[i] + data[i - 1]) * 0.5;
            }
          }

          sound.setBuffer(buffer);
          sound.setLoop(true);
          sound.play();
        }

        // Add sound to the mesh
        mesh.add(sound);

        // Store reference to the positional audio
        positionalAudios.push(sound);

        console.log(`Added Three.js positional audio to sphere ${index}`);
      } catch (e) {
        console.error("Error creating Three.js positional audio:", e);
      }
    }

    // Create audio components only if audio context is ready
    if (listener && Tone.context && Tone.context.state === "running") {
      try {
        // Determine if this sphere should use a GrainPlayer (only 1 in 10 spheres)
        const useGrainPlayer = index % 10 === 0;

        // Create velocity for the sphere
        const velocity = new THREE.Vector3(
          (Math.random() * 2 - 1) * (MAX_SPEED - MIN_SPEED) + MIN_SPEED,
          (Math.random() * 2 - 1) * (MAX_SPEED - MIN_SPEED) + MIN_SPEED,
          (Math.random() * 2 - 1) * (MAX_SPEED - MIN_SPEED) + MIN_SPEED,
        );

        // Select frequency - alternate between low and high octaves
        let frequency;
        if (index % 2 === 0) {
          // Lower octaves (55-220 Hz)
          frequency = 55 + Math.random() * 165;
        } else {
          // Higher octaves (220-880 Hz)
          frequency = 220 + Math.random() * 660;
        }

        // Create audio components based on type
        if (useGrainPlayer) {
          // Create a GrainPlayer with proper buffer loading (only for 1 in 10 spheres)
          const audioUrl = "/audio/heroic.mp3"; // Use local file

          // Create the GrainPlayer with lower volume
          const grainPlayer = new Tone.GrainPlayer({
            url: audioUrl,
            loop: true,
            grainSize: 0.1,
            overlap: 0.05,
            volume: -40, // Much lower volume
            playbackRate: 0.5 + Math.random(),
            onload: () => {
              console.log("GrainPlayer loaded for sphere", index);
              // Start with a 10% chance
              if (Math.random() < 0.1) {
                grainPlayer.start();
              }
            },
          });

          // Create a panner for spatial audio
          const panner = new Tone.Panner3D({
            positionX: mesh.position.x,
            positionY: mesh.position.y,
            positionZ: mesh.position.z,
            rolloffFactor: 2,
            distanceModel: "exponential",
            maxDistance: 10000,
            refDistance: 5,
          });

          // Connect to audio mixer instead of directly to destination
          grainPlayer.connect(panner);

          // Connect to mixer
          if (audioMixer) {
            audioMixer.connectNode(panner, "sphereGrainPlayers");
          } else {
            // Fallback to old connection method
            panner.toDestination();
            if (reverb) {
              panner.connect(reverb);
            }
          }

          // Return audio object with grain player
          return {
            mesh,
            velocity,
            frequency,
            grainPlayer,
            panner,
            lastUpdateTime: Date.now(),
          };
        } else {
          // Create a simple oscillator with chop effect
          const oscillator = new Tone.Oscillator({
            frequency: frequency,
            type: "sine",
            volume: -30,
          }).start();

          // Create a filter
          const filter = new Tone.Filter({
            type: "bandpass",
            frequency: frequency,
            Q: 2,
          });

          // Create a gain node
          const gain = new Tone.Gain(0.5);

          // Create a chopper effect (amplitude modulation)
          const chopRate = Math.random() * 9 + 1; // 1Hz to 10Hz
          const chopOsc = new Tone.Oscillator({
            frequency: chopRate,
            type: "square",
            volume: 0,
          }).start();

          // Create lowpass filter for smoother transitions in the chopping
          const chopFilter = new Tone.Filter({
            frequency: 30,
            type: "lowpass",
          });

          // Connect chop oscillator to filter
          chopOsc.connect(chopFilter);

          // Create gain node for the chopping effect
          const chopGain = new Tone.Gain();

          // Connect filter to gain node's gain parameter
          // Fix the linter error by explicitly specifying the gain parameter
          chopFilter.connect(chopGain.gain as unknown as Tone.Param<"gain">);

          // Connect oscillator to filter to chop gain to main gain
          oscillator.connect(filter);
          filter.connect(chopGain);
          chopGain.connect(gain);

          // Create a panner for spatial audio
          const panner = new Tone.Panner3D({
            positionX: mesh.position.x,
            positionY: mesh.position.y,
            positionZ: mesh.position.z,
            rolloffFactor: 2,
            distanceModel: "exponential",
            maxDistance: 10000,
            refDistance: 5,
          });

          // Connect to audio mixer instead of directly to destination
          gain.connect(panner);

          // Connect to mixer
          if (audioMixer) {
            audioMixer.connectNode(panner, "sphereOscillators");
          } else {
            // Fallback to old connection method
            panner.toDestination();
            if (reverb) {
              panner.connect(reverb);
            }
          }

          // Return audio object with oscillator
          return {
            mesh,
            velocity,
            frequency,
            oscillator,
            filter,
            gain,
            panner,
            chopOsc,
            chopFilter,
            chopGain,
            lastUpdateTime: Date.now(),
          };
        }
      } catch (e) {
        console.error("Error creating audio for sphere:", e);
      }
    }

    // Return minimal object if audio creation fails
    return {
      mesh,
      velocity: new THREE.Vector3(
        (Math.random() * 2 - 1) * (MAX_SPEED - MIN_SPEED) + MIN_SPEED,
        (Math.random() * 2 - 1) * (MAX_SPEED - MIN_SPEED) + MIN_SPEED,
        (Math.random() * 2 - 1) * (MAX_SPEED - MIN_SPEED) + MIN_SPEED,
      ),
      frequency: 220 + Math.random() * 440,
      lastUpdateTime: Date.now(),
    };
  };

  // Update audio object positions and handle collisions
  const updateAudioObjects = () => {
    // Skip if no listener
    if (!listener) return;

    const currentTime = Date.now();

    // Update moving light position for godray effect
    godrayParams.lightPos.x =
      Math.sin(currentTime * 0.0005) * SPACE_BOUNDS * 0.3;
    godrayParams.lightPos.y =
      Math.cos(currentTime * 0.0003) * SPACE_BOUNDS * 0.3 + SPACE_BOUNDS * 0.2;
    godrayParams.lightPos.z =
      Math.sin(currentTime * 0.0007) * SPACE_BOUNDS * 0.3;

    // Update spheres
    audioObjects.forEach((obj) => {
      // Skip if no mesh
      if (!obj.mesh) return;

      // Update position based on velocity
      obj.mesh.position.x += obj.velocity.x;
      obj.mesh.position.y += obj.velocity.y;
      obj.mesh.position.z += obj.velocity.z;

      // Boundary checks with bounce to keep within -10 to 10 range
      const halfBounds = 10; // Changed from SPACE_BOUNDS / 2 to exactly 10

      if (Math.abs(obj.mesh.position.x) > halfBounds) {
        obj.velocity.x *= -1;
        obj.mesh.position.x = Math.sign(obj.mesh.position.x) * halfBounds;
      }

      if (Math.abs(obj.mesh.position.y) > halfBounds) {
        obj.velocity.y *= -1;
        obj.mesh.position.y = Math.sign(obj.mesh.position.y) * halfBounds;
      }

      if (Math.abs(obj.mesh.position.z) > halfBounds) {
        obj.velocity.z *= -1;
        obj.mesh.position.z = Math.sign(obj.mesh.position.z) * halfBounds;
      }

      // Update material time uniform for godray effect
      if (obj.material && obj.material.uniforms && obj.material.uniforms.time) {
        obj.material.uniforms.time.value = currentTime * 0.001;
      }

      // Update grain player position if available
      if (obj.grainPlayer && grainPlayers.length > 0) {
        const grainPlayerData = grainPlayers.find(
          (data) => data.sphere === obj.mesh,
        );
        if (grainPlayerData && grainPlayerData.panner) {
          grainPlayerData.panner.positionX.value = obj.mesh.position.x;
          grainPlayerData.panner.positionY.value = obj.mesh.position.y;
          grainPlayerData.panner.positionZ.value = obj.mesh.position.z;
        }
      }

      // Calculate growth factor based on time
      const growthFactor =
        1 +
        Math.sin(currentTime * obj.growthSpeed + obj.pulsePhase) *
          SPHERE_GROWTH_FACTOR;

      // Apply growth to scale
      obj.mesh.scale.set(growthFactor, growthFactor, growthFactor);

      // Update transparency based on growth
      const transparency =
        SPHERE_MIN_TRANSPARENCY +
        (SPHERE_MAX_TRANSPARENCY - SPHERE_MIN_TRANSPARENCY) *
          ((growthFactor - 1) / SPHERE_GROWTH_FACTOR);

      // Apply transparency to material
      if (
        obj.material &&
        obj.material.uniforms &&
        obj.material.uniforms.transparency
      ) {
        obj.material.uniforms.transparency.value = transparency;
      } else if (obj.material && obj.material.opacity !== undefined) {
        obj.material.opacity = transparency;
      }
    });
  };

  const setupPostProcessing = () => {
    // Create composer
    composer = new EffectComposer(renderer);

    // Add render pass
    const renderPass = new RenderPass(scene, camera);
    composer.addPass(renderPass);

    // Add bloom pass for glow effect
    const bloomPass = new UnrealBloomPass(
      new THREE.Vector2(window.innerWidth, window.innerHeight),
      1.5, // strength
      0.4, // radius
      0.85, // threshold
    );
    composer.addPass(bloomPass);

    // No need for GodRaysPass since we don't have it
    // Instead, add a simple shader pass for color correction
    const colorCorrectionShader = {
      uniforms: {
        tDiffuse: { value: null },
        brightness: { value: 0.05 },
        contrast: { value: 1.1 },
        saturation: { value: 1.2 },
      },
      vertexShader: `
        varying vec2 vUv;
        void main() {
          vUv = uv;
          gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
        }
      `,
      fragmentShader: `
        uniform sampler2D tDiffuse;
        uniform float brightness;
        uniform float contrast;
        uniform float saturation;
        varying vec2 vUv;
        
        void main() {
          vec4 color = texture2D(tDiffuse, vUv);
          
          // Brightness
          color.rgb += brightness;
          
          // Contrast
          color.rgb = (color.rgb - 0.5) * contrast + 0.5;
          
          // Saturation
          float luminance = dot(color.rgb, vec3(0.299, 0.587, 0.114));
          color.rgb = mix(vec3(luminance), color.rgb, saturation);
          
          gl_FragColor = color;
        }
      `,
    };

    const colorCorrectionPass = new ShaderPass(colorCorrectionShader);
    composer.addPass(colorCorrectionPass);
  };

  const setupControls = () => {
    // Create orbit controls
    controls = new OrbitControls(camera, renderer.domElement);
    controls.enableDamping = true;
    controls.dampingFactor = 0.05;
    controls.screenSpacePanning = false;
    controls.minDistance = 10;
    controls.maxDistance = 50;
    controls.maxPolarAngle = Math.PI / 1.5;
    controls.autoRotate = true;
    controls.autoRotateSpeed = 0.5;

    // Add random camera rotation on all axes
    const randomRotateCamera = () => {
      // Create random target rotation values
      const targetX = (Math.random() * Math.PI) / 4 - Math.PI / 8; // -22.5 to 22.5 degrees
      const targetY = (Math.random() * Math.PI) / 4 - Math.PI / 8;
      const targetZ = (Math.random() * Math.PI) / 8 - Math.PI / 16; // smaller Z rotation (-11.25 to 11.25 degrees)

      // Create tween for smooth rotation
      new TWEEN.Tween(camera.rotation)
        .to({ x: targetX, y: targetY, z: targetZ }, 10000) // 10 seconds
        .easing(TWEEN.Easing.Sinusoidal.InOut)
        .onComplete(() => {
          // Schedule next random rotation
          setTimeout(randomRotateCamera, Math.random() * 5000 + 5000); // 5-10 seconds delay
        })
        .start();
    };

    // Start random camera rotation after a delay
    setTimeout(randomRotateCamera, 5000);
  };

  // Add a visible button to start audio if it doesn't start automatically
  const addAudioStartButton = () => {
    // Check if button already exists
    if (document.getElementById("start-audio-btn")) return;

    // Create button
    const button = document.createElement("button");
    button.id = "start-audio-btn";
    button.textContent = "Start Audio Experience";
    button.style.position = "fixed";
    button.style.top = "50%";
    button.style.left = "50%";
    button.style.transform = "translate(-50%, -50%)";
    button.style.zIndex = "1000";
    button.style.padding = "15px 30px";
    button.style.backgroundColor = "rgba(0, 0, 0, 0.8)";
    button.style.color = "#fff";
    button.style.border = "2px solid #0ff";
    button.style.borderRadius = "5px";
    button.style.fontFamily = "sans-serif";
    button.style.fontSize = "18px";
    button.style.cursor = "pointer";
    button.style.boxShadow = "0 0 20px rgba(0, 255, 255, 0.5)";

    // Add hover effect
    button.onmouseover = () => {
      button.style.backgroundColor = "rgba(0, 0, 0, 0.9)";
      button.style.boxShadow = "0 0 25px rgba(0, 255, 255, 0.7)";
    };
    button.onmouseout = () => {
      button.style.backgroundColor = "rgba(0, 0, 0, 0.8)";
      button.style.boxShadow = "0 0 20px rgba(0, 255, 255, 0.5)";
    };

    // Add click handler
    button.onclick = async () => {
      try {
        // Start Tone.js
        await Tone.start();
        console.log("Tone.js started from button click");

        // Resume audio context
        if (Tone.context && Tone.context.state !== "running") {
          await Tone.context.resume();
        }

        // Update modules with the running context
        if (cubeModule) {
          cubeModule.updateAudioContext(Tone.context);
        }

        if (sphereModule) {
          sphereModule.updateAudioContext(Tone.context);
        }

        // Remove button after successful start
        button.remove();
      } catch (e) {
        console.error("Error starting audio from button:", e);
        button.textContent = "Retry Audio";
      }
    };

    // Add to document
    document.body.appendChild(button);
  };

  // Set up audio
  const setupAudio = async () => {
    try {
      console.log("Setting up audio...");

      // Create Three.js audio listener
      threeAudioListener = new THREE.AudioListener();
      camera.add(threeAudioListener);
      console.log("Three.js audio listener created and added to camera");

      // Check if Tone.js is already started
      if (Tone.context.state === "running") {
        console.log("Tone.js is already running");
      } else {
        console.log("Tone.js is not running, starting...");
        await Tone.start();
      }

      // Initialize audio mixer
      audioMixer = AudioMixer();
      const mixerComponents = audioMixer.init();
      console.log("Audio mixer initialized");

      // Make mixer globally accessible for new audio nodes
      // @ts-ignore - Adding audioMixer to window for global access
      window.audioMixer = audioMixer;

      // Use the mixer's reverb instead of creating a new one
      reverb = mixerComponents.reverbNode;
      console.log("Using mixer's reverb node");

      // Set up listener
      listener = new THREE.AudioListener();
      camera.add(listener);

      console.log("Audio setup complete. Context state:", Tone.context.state);

      // Set up audio context resumption handlers
      setupAudioContextResumption();

      // Add visible button if audio context is not running
      if (Tone.context.state !== "running") {
        addAudioStartButton();
      }

      // Load GLB model
      loadFloatingModel();

      return true;
    } catch (error) {
      console.error("Audio setup error:", error);
      // Add visible button if there was an error
      addAudioStartButton();
      return false;
    }
  };

  // Load GLB model
  const loadFloatingModel = () => {
    // Import GLTFLoader dynamically
    import("three/examples/jsm/loaders/GLTFLoader.js")
      .then(({ GLTFLoader }) => {
        const loader = new GLTFLoader();

        // Load the model
        loader.load(
          "https://boytchev.github.io/etudes/threejs/negative-morphs/LeePerrySmith.glb",
          (gltf) => {
            console.log("GLB model loaded successfully");

            // Get the model
            floatingModel = gltf.scene.children[0];

            // Scale the model (make it giant)
            floatingModel.scale.set(3.0, 3.0, 3.0);

            // Create custom material with low opacity and emissive glow
            floatingModel.material = new THREE.MeshPhysicalMaterial({
              color: 0xffd000,
              sheen: 1,
              sheenColor: "white",
              sheenRoughness: 0.25,
              metalness: 0,
              roughness: 0.5,
              emissive: "orange",
              emissiveIntensity: 0.5,
              transparent: true,
              opacity: 0.05, // Very low opacity (5%)
            });

            // Position the model
            floatingModel.position.set(0, 0, 0);

            // Add Three.js positional audio to the model
            if (threeAudioListener) {
              // Create a positional audio source
              const sound = new THREE.PositionalAudio(threeAudioListener);

              // Configure positional audio parameters
              sound.setRefDistance(5);
              sound.setDistanceModel("exponential");
              sound.setRolloffFactor(2);
              sound.setVolume(0.5);

              // Load audio file for the model
              const audioLoader = new THREE.AudioLoader();
              audioLoader.load(
                "/audio/heroic.mp3", // Use existing audio file
                (buffer) => {
                  sound.setBuffer(buffer);
                  sound.setLoop(true);
                  sound.play();

                  // Connect to audio mixer
                  if (audioMixer) {
                    audioMixer.connectThreeAudio(sound, "floatingModelAudio");
                  }

                  console.log(
                    "Positional audio loaded and playing on floating model",
                  );
                },
                (progress) => {
                  console.log(
                    `Loading audio: ${Math.round((progress.loaded / progress.total) * 100)}%`,
                  );
                },
                (error) => {
                  console.error("Error loading audio:", error);
                },
              );

              // Add sound to the model
              floatingModel.add(sound);

              // Store reference to the positional audio
              positionalAudios.push(sound);

              console.log("Added Three.js positional audio to floating model");
            } else {
              console.warn("Audio listener not available for positional audio");
            }

            // Add to scene
            scene.add(floatingModel);

            console.log("Floating model added to scene");
          },
          (progress) => {
            console.log(
              `Loading model: ${(progress.loaded / progress.total) * 100}%`,
            );
          },
          (error) => {
            console.error("Error loading GLB model:", error);
          },
        );
      })
      .catch((error) => {
        console.error("Error importing GLTFLoader:", error);
      });
  };

  const handleScroll = () => {
    // Get scroll position and window height
    const scrollPosition = window.scrollY;
    const windowHeight = window.innerHeight;

    // Calculate how far down the page we've scrolled as a percentage
    // We'll use this to fade out the audio
    // Using a smaller divisor (windowHeight/3) to make the fade happen faster
    const scrollPercentage = Math.min(scrollPosition / (windowHeight / 3), 1);

    // Only proceed if Tone.js is started
    if (toneStarted) {
      // Adjust Tone.js master volume based on scroll position
      // Map from 0 to 1 (scroll percentage) to initial volume to -70 (silent)
      // Using a more aggressive curve with Math.pow for faster initial drop
      const fadeIntensity = Math.pow(scrollPercentage, 0.7); // Adjust power for curve shape
      const targetVolume = initialVolume - fadeIntensity * 70;

      // Apply volume change with smoothing
      if (Math.abs(Tone.getDestination().volume.value - targetVolume) > 0.1) {
        // Faster ramp time for more immediate effect
        Tone.getDestination().volume.rampTo(targetVolume, 0.05);

        // Also adjust Three.js audio listener gain if available
        if (listener && listener.gain) {
          const listenerGain = 1 - fadeIntensity;
          listener.gain.gain.value = listenerGain;
        }

        // Log volume changes for debugging
        if (Math.abs(lastScrollY - scrollPosition) > 20) {
          console.log(
            `Scroll: ${scrollPercentage.toFixed(2)}, Intensity: ${fadeIntensity.toFixed(2)}, Volume: ${targetVolume.toFixed(2)}dB`,
          );
          lastScrollY = scrollPosition;
        }
      }

      // If we've scrolled more than 50% of our fade threshold, pause any playing sounds
      if (scrollPercentage > 0.5) {
        // Optional: pause or stop specific sounds when scrolled far down
        // This could be implemented if needed
      }
    }
  };

  // Set up Three.js scene
  const setupScene = () => {
    // Set up renderer
    renderer.setSize(window.innerWidth, window.innerHeight);
    renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));
    renderer.setClearColor(0x000000, 0); // Transparent background

    // Set up camera
    camera.position.z = 15; // Increased from 5 to see more of the scene
    camera.position.y = 5; // Slight elevation for better perspective

    // Add ambient light
    const ambientLight = new THREE.AmbientLight(0xffffff, 0.5);
    scene.add(ambientLight);

    // Add directional light
    const directionalLight = new THREE.DirectionalLight(0xffffff, 1);
    directionalLight.position.set(5, 5, 5);
    scene.add(directionalLight);

    // Add the renderer to the DOM
    const container = document.getElementById("three-container");
    if (container) {
      // Clear any existing canvas
      while (container.firstChild) {
        container.removeChild(container.firstChild);
      }
      container.appendChild(renderer.domElement);
      console.log("Renderer added to DOM");
    } else {
      console.error("Could not find three-container element");
    }

    // Handle window resize
    window.addEventListener("resize", () => {
      // Update camera
      camera.aspect = window.innerWidth / window.innerHeight;
      camera.updateProjectionMatrix();

      // Update renderer
      renderer.setSize(window.innerWidth, window.innerHeight);

      // Update composer if it exists
      if (composer) {
        composer.setSize(window.innerWidth, window.innerHeight);
      }
    });

    console.log("Scene setup complete");
  };

  // Create HUD element to display camera position and rotation
  const createHUD = () => {
    hudElement = document.createElement("div");
    hudElement.style.position = "absolute";
    hudElement.style.bottom = "20px";
    hudElement.style.right = "20px";
    hudElement.style.padding = "10px";
    hudElement.style.backgroundColor = "transparent";
    hudElement.style.color = "#aaaaaa";
    hudElement.style.fontFamily = "monospace";
    hudElement.style.fontSize = "12px";
    hudElement.style.borderRadius = "5px";
    hudElement.style.zIndex = "1000";
    hudElement.style.pointerEvents = "none"; // Don't interfere with mouse events
    hudElement.style.textAlign = "right";

    // Add to DOM
    document.body.appendChild(hudElement);

    // Add toggle key for HUD visibility
    document.addEventListener("keydown", (e: KeyboardEvent) => {
      if (e.key === "h" || e.key === "H") {
        hudVisible = !hudVisible;
        if (hudElement) {
          hudElement.style.display = hudVisible ? "block" : "none";
        }
      }
    });
  };

  // Set up modules
  const setupModules = () => {
    // Initialize cube module
    cubeModule = CubeModule();
    cubeModule.init(scene, listener, reverb);
    // Explicitly start cube animation
    cubeModule.startCubeAnimation();

    // Initialize pulse module
    pulseModule = PulseModule();
    pulseModule.init(scene, listener, reverb);

    // Initialize sphere module
    sphereModule = SphereModule();
    sphereModule.init(scene, listener, reverb);

    console.log("Modules initialized");
  };

  // Modify cubeModule to add movement
  const enhanceCubeModule = () => {
    if (!cubeModule || !cubeModule.getCubes) return;

    // Get the cubes from the cubeModule
    const cubes = cubeModule.getCubes();
    if (!cubes) return;

    // Add velocity to each cube
    cubes.forEach((cube: any) => {
      if (!cube.userData) cube.userData = {};

      // Add random velocity if not already present
      if (!cube.userData.velocity) {
        cube.userData.velocity = new THREE.Vector3(
          (Math.random() - 0.5) * 0.02,
          (Math.random() - 0.5) * 0.02,
          (Math.random() - 0.5) * 0.02,
        );
      }

      // Add random rotation velocity if not already present
      if (!cube.userData.rotationVelocity) {
        cube.userData.rotationVelocity = new THREE.Vector3(
          (Math.random() - 0.5) * 0.01,
          (Math.random() - 0.5) * 0.01,
          (Math.random() - 0.5) * 0.01,
        );
      }

      // Scale cube size
      cube.scale.set(
        CUBE_SIZE_MULTIPLIER,
        CUBE_SIZE_MULTIPLIER,
        CUBE_SIZE_MULTIPLIER,
      );

      // Apply matcap material for translucency
      if (cube.material) {
        // Create matcap texture
        const matcapTexture = new THREE.TextureLoader().load(
          "/matcap/bluew.jpg",
        );

        // Create matcap material
        const matcapMaterial = new THREE.MeshMatcapMaterial({
          matcap: matcapTexture,
          transparent: true,
          opacity: 0.3, // 70% translucent
          side: THREE.DoubleSide,
        });

        // Apply material
        cube.material = matcapMaterial;
      }
    });
  };

  // Initialize function to set up everything
  const initialize = async () => {
    try {
      console.log("Initializing Three.js scene");

      // Set up renderer
      renderer.setSize(window.innerWidth, window.innerHeight);
      renderer.setPixelRatio(window.devicePixelRatio);
      renderer.setClearColor(0x000022, 1);

      // Find the container element
      const container = document.getElementById("three-container");
      if (!container) {
        console.error("Could not find three-container element");
        return;
      }

      // Append renderer to container
      container.appendChild(renderer.domElement);

      // Set up camera
      camera.position.set(0, 5, 15);

      // Set up controls
      controls = new OrbitControls(camera, renderer.domElement);
      controls.enableDamping = true;
      controls.dampingFactor = 0.05;
      controls.minDistance = 10;
      controls.maxDistance = 50;
      controls.maxPolarAngle = Math.PI / 1.5;
      controls.autoRotate = true;
      controls.autoRotateSpeed = 0.5;

      // Set up random camera rotation
      setupControls();

      // Set up lighting
      const ambientLight = new THREE.AmbientLight(0x333333);
      scene.add(ambientLight);

      // Add directional light
      const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8);
      directionalLight.position.set(5, 10, 7.5);
      scene.add(directionalLight);

      // Create post-processing composer
      composer = new EffectComposer(renderer);

      // Add render pass
      const renderPass = new RenderPass(scene, camera);
      composer.addPass(renderPass);

      // Add bloom pass
      const bloomPass = new UnrealBloomPass(
        new THREE.Vector2(window.innerWidth, window.innerHeight),
        1.5, // strength
        0.4, // radius
        0.85, // threshold
      );
      composer.addPass(bloomPass);

      // Add color correction pass
      const colorCorrectionShader = {
        uniforms: {
          tDiffuse: { value: null },
          saturation: { value: 1.2 },
          brightness: { value: 1.1 },
          contrast: { value: 1.1 },
        },
        vertexShader: `
          varying vec2 vUv;
          void main() {
            vUv = uv;
            gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
          }
        `,
        fragmentShader: `
          uniform sampler2D tDiffuse;
          uniform float saturation;
          uniform float brightness;
          uniform float contrast;
          varying vec2 vUv;
          
          void main() {
            vec4 color = texture2D(tDiffuse, vUv);
            
            // Apply brightness
            color.rgb *= brightness;
            
            // Apply contrast
            color.rgb = (color.rgb - 0.5) * contrast + 0.5;
            
            // Apply saturation
            float luminance = dot(color.rgb, vec3(0.299, 0.587, 0.114));
            color.rgb = mix(vec3(luminance), color.rgb, saturation);
            
            gl_FragColor = color;
          }
        `,
      };

      const colorCorrectionPass = new ShaderPass(colorCorrectionShader);
      composer.addPass(colorCorrectionPass);

      // Create lighting bars
      for (let i = 0; i < 10; i++) {
        const bar = createLightingBar(i);
        lightingBars.push(bar);
      }

      // Create audio objects
      for (let i = 0; i < 8; i++) {
        const obj = createAudioObject(i);
        audioObjects.push(obj);
      }

      // Set up audio with retry mechanism
      await startAudioWithRetry();

      // Set up window resize handler
      window.addEventListener("resize", () => {
        camera.aspect = window.innerWidth / window.innerHeight;
        camera.updateProjectionMatrix();
        renderer.setSize(window.innerWidth, window.innerHeight);
        composer.setSize(window.innerWidth, window.innerHeight);
      });

      // Start animation loop
      animate();

      console.log("Three.js scene initialized successfully");

      // Show start button if audio context is not running
      if (Tone.context && Tone.context.state !== "running") {
        const startButton = document.getElementById("start-audio-btn");
        if (startButton) {
          startButton.style.display = "block";
          startButton.addEventListener("click", async () => {
            await startAudioWithRetry();
            startButton.style.display = "none";
          });
        }
      }

      return true;
    } catch (error) {
      console.error("Error initializing scene:", error);
      return false;
    }
  };

  // Start audio with retry mechanism
  const startAudioWithRetry = async (maxRetries = 3) => {
    let retries = 0;
    let success = false;

    while (!success && retries < maxRetries) {
      try {
        console.log(`Attempt ${retries + 1} to start audio`);

        // Start Tone.js
        await Tone.start();
        console.log("Tone.js started successfully");

        // Set up audio
        await setupAudio();

        // Create modules
        cubeModule = CubeModule();
        cubeModule.init(scene, listener, reverb);
        // Explicitly start cube animation
        cubeModule.startCubeAnimation();

        sphereModule = SphereModule();
        sphereModule.init(scene, listener, reverb);

        pulseModule = PulseModule();
        pulseModule.init(scene, listener, reverb);

        // Connect module audio to mixer if available
        if (audioMixer) {
          // Connect cube oscillators to mixer
          try {
            setTimeout(() => {
              try {
                const cubeOscillators = cubeModule.getOscillators
                  ? cubeModule.getOscillators()
                  : [];
                if (cubeOscillators && cubeOscillators.length > 0) {
                  cubeOscillators.forEach((osc: any) => {
                    audioMixer.connectNode(osc, "cubeOscillators");
                  });
                  console.log(
                    "Connected cube oscillators to mixer:",
                    cubeOscillators.length,
                  );
                } else {
                  console.warn("No cube oscillators found to connect to mixer");
                }
              } catch (e) {
                console.error("Error connecting cube oscillators to mixer:", e);
              }
            }, 1000); // Delay to ensure modules are fully initialized
          } catch (e) {
            console.error("Error setting up cube oscillator connection:", e);
          }

          // Connect sphere oscillators to mixer
          try {
            setTimeout(() => {
              try {
                const sphereOscillators = sphereModule.getOscillators
                  ? sphereModule.getOscillators()
                  : [];
                if (sphereOscillators && sphereOscillators.length > 0) {
                  sphereOscillators.forEach((osc: any) => {
                    audioMixer.connectNode(osc, "sphereOscillators");
                  });
                  console.log(
                    "Connected sphere oscillators to mixer:",
                    sphereOscillators.length,
                  );
                } else {
                  console.warn(
                    "No sphere oscillators found to connect to mixer",
                  );
                }
              } catch (e) {
                console.error(
                  "Error connecting sphere oscillators to mixer:",
                  e,
                );
              }
            }, 1000); // Delay to ensure modules are fully initialized
          } catch (e) {
            console.error("Error setting up sphere oscillator connection:", e);
          }

          // Connect pulse oscillators to mixer
          try {
            setTimeout(() => {
              try {
                const pulseOscillators = pulseModule.getOscillators
                  ? pulseModule.getOscillators()
                  : [];
                if (pulseOscillators && pulseOscillators.length > 0) {
                  pulseOscillators.forEach((osc: any) => {
                    audioMixer.connectNode(osc, "pulseOscillators");
                  });
                  console.log("Connected pulse oscillators to mixer");
                }
              } catch (e) {
                console.error(
                  "Error connecting pulse oscillators to mixer:",
                  e,
                );
              }
            }, 1000); // Delay to ensure modules are fully initialized
          } catch (e) {
            console.error("Error setting up pulse oscillator connection:", e);
          }
        }

        // Set up audio context resumption handlers
        setupAudioContextResumption();

        // Mark as started
        toneStarted = true;
        success = true;

        console.log("Audio setup complete");

        // Hide start button if it exists
        const startButton = document.getElementById("start-audio-btn");
        if (startButton) {
          startButton.style.display = "none";
        }

        return true;
      } catch (error) {
        console.error(`Error starting audio (attempt ${retries + 1}):`, error);
        retries++;

        // Wait before retrying
        await new Promise((resolve) => setTimeout(resolve, 1000));
      }
    }

    if (!success) {
      console.error("Failed to start audio after multiple attempts");

      // Show start button as fallback
      const startButton = document.getElementById("start-audio-btn");
      if (startButton) {
        startButton.style.display = "block";
      } else {
        addAudioStartButton();
      }

      return false;
    }
  };

  // Animation loop
  const animate = () => {
    requestAnimationFrame(animate);

    // Update TWEEN
    TWEEN.update();

    // Get delta time for smooth animations
    const deltaTime = clock.getDelta();
    const now = Date.now() * 0.001; // Current time in seconds

    // Update modules
    if (sphereModule) {
      sphereModule.updateSpheres();
    }

    if (cubeModule) {
      cubeModule.updateCubes();
      // Also update cube materials for transitions
      if (typeof cubeModule.updateMaterials === "function") {
        cubeModule.updateMaterials(deltaTime * 1000); // Convert to milliseconds
      }
    }

    // Update lighting bars
    updateLightingBars(deltaTime, now);

    // Update audio objects
    updateAudioObjects();

    // Update floating model if it exists
    if (floatingModel) {
      floatingModel.rotation.y += 0.001;
    }

    // Update composer or renderer
    if (composer) {
      composer.render();
    } else if (renderer && scene && camera) {
      renderer.render(scene, camera);
    }
  };

  // Set up event listeners
  document.addEventListener("DOMContentLoaded", () => {
    console.log("DOM content loaded, initializing...");
    initialize();
  });

  // Listen for audioContextReady event (dispatched from index.astro)
  window.addEventListener("audioContextReady", async () => {
    console.log("audioContextReady event received");

    // Start Tone.js if not already started
    if (!toneStarted) {
      try {
        // Create a synthetic click event to start audio
        setTimeout(async () => {
          await startAudioWithRetry();
        }, 500);
      } catch (e) {
        console.error("Error starting Tone.js:", e);
      }
    }
  });

  // Add event listeners to ensure audio context stays running
  ["click", "touchstart", "keydown"].forEach((eventType) => {
    document.addEventListener(eventType, async () => {
      if (Tone.context && Tone.context.state !== "running") {
        try {
          await Tone.context.resume();
          console.log("Audio context resumed after user interaction");

          // Update modules with the resumed context
          if (cubeModule) cubeModule.updateAudioContext(Tone.context);
          if (sphereModule) sphereModule.updateAudioContext(Tone.context);
          if (pulseModule) pulseModule.updateAudioContext(Tone.context);
          if (audioMixer) audioMixer.updateAudioContext(Tone.context);
        } catch (e) {
          console.error("Error resuming audio context:", e);
        }
      }
    });
  });

  // Resume audio context when window gains focus
  window.addEventListener("focus", async () => {
    if (Tone.context && Tone.context.state !== "running") {
      try {
        await Tone.context.resume();
        console.log("Audio context resumed on window focus");

        // Update modules with the resumed context
        if (cubeModule) cubeModule.updateAudioContext(Tone.context);
        if (sphereModule) sphereModule.updateAudioContext(Tone.context);
        if (pulseModule) pulseModule.updateAudioContext(Tone.context);
        if (audioMixer) audioMixer.updateAudioContext(Tone.context);
      } catch (e) {
        console.error("Error resuming audio context on focus:", e);
      }
    }
  });
</script>
